{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rUlkBjM5BdFf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## General Configs\n",
        "\n",
        "max_len = 200\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "latent_dim = 256"
      ],
      "metadata": {
        "id": "PJscwmB5B13p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing IMDB data for the text classification problem\n",
        "\n",
        "## Only importing the train data, igoring the test data that's why kepping\n",
        "## the underscor for that.\n",
        "\n",
        "(X_train,y_train),_ = tf.keras.datasets.imdb.load_data(num_words=vocab_size)"
      ],
      "metadata": {
        "id": "35GCsFYECAmm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)\n",
        "len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXHIz5GPCcVX",
        "outputId": "e1bfb66b-4887-4887-9c89-b086f035f4dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Taking the subset of data for the training\n",
        "\n",
        "X_train = X_train[:3000]\n",
        "y_train = y_train[:3000]\n",
        "\n",
        "len(X_train)\n",
        "len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDX5jYXjCtDf",
        "outputId": "cf130f5c-101e-4f01-8f1d-071355d5f82a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the padding. Because each sentences will have the different lengths. So we need to keep all in one length\n",
        "\n",
        "X_train = pad_sequences(X_train,maxlen=max_len, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "JwTO3IbVDXf_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the LSTM Model with Keras\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim)(input_layer)\n",
        "lstm_layer, state_h, state_c = LSTM(latent_dim, return_state=True)(embedding_layer)\n",
        "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
        "\n",
        "classification_model = Model(input_layer, output_layer)"
      ],
      "metadata": {
        "id": "UbsMBdATDxUu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "raVZOQd-E-1-",
        "outputId": "1c794eba-2d0f-43ed-f40a-52a6e1339f40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m1,280,000\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   â”‚       \u001b[38;5;34m394,240\u001b[0m â”‚\n",
              "â”‚                                 â”‚ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]     â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> â”‚\n",
              "â”‚                                 â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]     â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,674,497\u001b[0m (6.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,497</span> (6.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,674,497\u001b[0m (6.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,497</span> (6.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Compiling the model\n",
        "\n",
        "classification_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OeiJhqTKFE9n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the model\n",
        "\n",
        "classification_model.fit(X_train, y_train, batch_size=64, epochs=1, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cuPXN2lFPxe",
        "outputId": "5ead4a27-68b6-4e13-bda2-d630e1a561e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.4748 - loss: 0.6950 - val_accuracy: 0.5567 - val_loss: 0.6930\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a1880879dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Code to decode the embedding into the text for testing purpose\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "def decoded_review(encoded_review):\n",
        "\n",
        "  word_index = imdb.get_word_index()\n",
        "\n",
        "  reverse_word_index = {index + 3: word for word, index in word_index.items()}\n",
        "\n",
        "  reverse_word_index[0] = \"\"\n",
        "  reverse_word_index[1] = \"\"\n",
        "  reverse_word_index[2] = \"\"\n",
        "  reverse_word_index[3] = \"\"\n",
        "\n",
        "  # Decode the review\n",
        "  decoded_review = \" \".join([reverse_word_index.get(i, \"\") for i in encoded_review[0]])\n",
        "\n",
        "  print(\"****Decoded Review:****\")\n",
        "  print(decoded_review)"
      ],
      "metadata": {
        "id": "s7GGT2xdGFEP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Predict the sentiment\n",
        "\n",
        "sample_review = X_train[1].reshape(1, -1)  # 1 sample with shape (1, max_len)\n",
        "print(\"Sample Review :\", decoded_review(sample_review))\n",
        "prediction = classification_model.predict(sample_review)\n",
        "\n",
        "print(\"Predicted sentiment probability:\", prediction[0][0])\n",
        "print(\"Predicted Sentiment:\", \"Positive ğŸ˜Š\" if prediction[0][0] > 0.5 else \"Negative ğŸ˜\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxxNoqk5FgD7",
        "outputId": "e88d84c1-dcea-44bb-ecfa-6eb1d212fbf9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****Decoded Review:****\n",
            " big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal  the hair is big lots of boobs  men wear those cut  shirts that show off their  sickening that men actually wore them and the music is just  trash that plays over and over again in almost every scene there is trashy music boobs and  taking away bodies and the gym still doesn't close for  all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then           \n",
            "Sample Review : None\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step\n",
            "Predicted sentiment probability: 0.50338\n",
            "Predicted Sentiment: Positive ğŸ˜Š\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save the model\n",
        "\n",
        "classification_model.save(\"lstm_imdb_classification_model.keras\")"
      ],
      "metadata": {
        "id": "LWv90aFdFwg0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retraining or Finetunning the same model with different data\n"
      ],
      "metadata": {
        "id": "2oR4_qJDLtkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 200\n",
        "vocab_size = 1000\n",
        "embedding_dim = 128\n",
        "latent_dim = 256\n",
        "\n",
        "# Load IMDB dataset\n",
        "(X_train, y_train), _ = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        ""
      ],
      "metadata": {
        "id": "C93JaIS0LrcL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[:1000]\n",
        "y_train = y_train[:1000]"
      ],
      "metadata": {
        "id": "EMKLLC8qL4-u"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgPwnjxwSkH9",
        "outputId": "26094bc2-70d6-4469-ce7e-f6e1753933b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## load the model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "load_classification_model = load_model(\"lstm_imdb_classification_model.keras\")"
      ],
      "metadata": {
        "id": "cVgeGQCwL9Wb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Limitations\n",
        "\n",
        "In LSTM (a type of RNN), training happens sequentially â€” the model processes one token at a time and passes information forward through hidden states.\n",
        "Because of this, LSTMs struggle to remember very long contexts: even though they have a â€œlong-term memory,â€ it fades as sequences grow longer.\n",
        "When retraining or fine-tuning with a lot of new data, the model can gradually overwrite or forget older information.\n",
        "This makes it difficult for LSTMs to efficiently handle very large datasets or maintain knowledge across long contexts.\n"
      ],
      "metadata": {
        "id": "oozdsuWoNLxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## compile and train the model\n",
        "\n",
        "load_classification_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "load_classification_model.fit(X_train, y_train, batch_size=64, epochs=1, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuTO5ZcSMZiZ",
        "outputId": "0c3834f7-9fef-4360-cb3b-c1ffc6d05c87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.4989 - loss: 0.6916 - val_accuracy: 0.6100 - val_loss: 0.6887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a17dc5a9100>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save the model\n",
        "\n",
        "load_classification_model.save(\"lstm_imdb_classification_model_updated.keras\")"
      ],
      "metadata": {
        "id": "fwtL5lfnMu6t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrain the model for the Summerization Task\n",
        "\n",
        "For a text classification task, we typically use an LSTM in a many-to-one architecture â€” the model reads the whole sequence and outputs a single class label.\n",
        "\n",
        "However, for a summarization task, we need to generate another sequence as output. This requires an encoder-decoder (sequence-to-sequence) architecture.\n",
        "\n",
        "Therefore, we canâ€™t reuse the same LSTM model designed for classification â€” we must redesign and retrain a new one for summarization.\n",
        "\n",
        "In contrast, Transformers use a single, unified architecture that can handle multiple tasks (classification, summarization, translation, etc.) simply by fine-tuning.\n",
        "\n",
        "LSTMs are still useful for smaller, task-specific problems, but Transformers are more general and powerful for large-scale NLP.\n"
      ],
      "metadata": {
        "id": "yRfaos4DOjLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_classification_model = load_model(\"lstm_imdb_classification_model_updated.keras\")"
      ],
      "metadata": {
        "id": "wwfdWqDbOfsB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_classification_model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9_8ozXkRDjj",
        "outputId": "7e05c9c7-584d-4eeb-b0d9-2ce290516f51"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<InputLayer name=input_layer, built=True>,\n",
              " <Embedding name=embedding, built=True>,\n",
              " <LSTM name=lstm, built=True>,\n",
              " <Dense name=dense, built=True>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoder\n",
        "\n",
        "encoder_input_layer = Input(shape=(max_len,), name='encoder_input')\n",
        "encoder_embedding = updated_classification_model.layers[1](encoder_input_layer)\n",
        "encoder_output, state_h, state_c = updated_classification_model.layers[2](encoder_embedding)"
      ],
      "metadata": {
        "id": "QWpsJxyuOrf0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_layer.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h55eQgjoS1QZ",
        "outputId": "c2360d3a-21c3-4b45-df73-76e187e8d30a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Decoder\n",
        "\n",
        "output_vocab_size = 8000\n",
        "target_max_len = 50\n",
        "\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(output_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "IFSHvltUO-Mj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Seq2Seq Model (Encoder-Decoder)\n",
        "\n",
        "seq2seq_model = Model([encoder_input_layer, decoder_inputs], decoder_outputs) # Use the correct input layer\n",
        "seq2seq_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0IjjAERCPJnh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data\n",
        "\n",
        "encoder_input_data = X_train[:1000]  # using IMDB input for now\n",
        "decoder_input_data = np.random.randint(1, output_vocab_size, (1000, target_max_len))\n",
        "decoder_target_data = np.random.randint(1, output_vocab_size, (1000, target_max_len, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUvXi3cNQhKB",
        "outputId": "adc7d773-bdf9-49b8-92e4-9a55c42379b8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of encoder_input_data: (1000, 200)\n",
            "Shape of decoder_input_data: (1000, 50)\n",
            "Shape of decoder_target_data: (1000, 50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_model.fit(\n",
        "    [encoder_input_data, decoder_input_data], # encoder_input_data should have shape (None, max_len)\n",
        "    decoder_target_data,\n",
        "    batch_size=32,\n",
        "    epochs=1,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vf0O0GTQm3u",
        "outputId": "a16c8541-53ef-425f-9044-2aa967b67d42"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 1.2760e-04 - loss: 8.9872 - val_accuracy: 0.0000e+00 - val_loss: 8.9875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a17e50a82f0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7HmHnN6QrJo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}